{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "backpropagation_algorithm",
      "provenance": [],
      "authorship_tag": "ABX9TyMttyxpmlCkEwdNK8fnrOP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/death-angel-141/BackPropagation_algorithm/blob/main/backpropagation_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh7M4wXi4yMe"
      },
      "source": [
        "pip install python-mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFXK9c--3YuG"
      },
      "source": [
        "import numpy as np\n",
        "import datasets.mnist.loader as mnist\n",
        "import matplotlib.pylab as plt\n",
        " \n",
        "class ANN:\n",
        "    def __init__(self, layers_size):\n",
        "        self.layers_size = layers_size\n",
        "        self.parameters = {}\n",
        "        self.L = len(self.layers_size)\n",
        "        self.n = 0\n",
        "        self.costs = []\n",
        "       \n",
        "    def sigmoid(self, Z):\n",
        "        return 1 / (1 + np.exp(-Z))\n",
        " \n",
        "    def initialize_parameters(self):\n",
        "        np.random.seed(1)\n",
        " \n",
        "        for l in range(1, len(self.layers_size)):\n",
        "            self.parameters[\"W\" + str(l)] = np.random.randn(self.layers_size[l], self.layers_size[l - 1]) / np.sqrt(\n",
        "                self.layers_size[l - 1])\n",
        "            self.parameters[\"b\" + str(l)] = np.zeros((self.layers_size[l], 1))\n",
        " \n",
        "    def forward(self, X):\n",
        "        store = {}\n",
        " \n",
        "        A = X.T\n",
        "        for l in range(self.L - 1):\n",
        "            Z = self.parameters[\"W\" + str(l + 1)].dot(A) + self.parameters[\"b\" + str(l + 1)]\n",
        "            A = self.sigmoid(Z)\n",
        "            store[\"A\" + str(l + 1)] = A\n",
        "            store[\"W\" + str(l + 1)] = self.parameters[\"W\" + str(l + 1)]\n",
        "            store[\"Z\" + str(l + 1)] = Z\n",
        " \n",
        "        Z = self.parameters[\"W\" + str(self.L)].dot(A) + self.parameters[\"b\" + str(self.L)]\n",
        "        A = self.sigmoid(Z)\n",
        "        store[\"A\" + str(self.L)] = A\n",
        "        store[\"W\" + str(self.L)] = self.parameters[\"W\" + str(self.L)]\n",
        "        store[\"Z\" + str(self.L)] = Z\n",
        " \n",
        "        return A, store\n",
        " \n",
        "    def sigmoid_derivative(self, Z):\n",
        "        s = 1 / (1 + np.exp(-Z))\n",
        "        return s * (1 - s)\n",
        " \n",
        "    def backward(self, X, Y, store):\n",
        " \n",
        "        derivatives = {}\n",
        " \n",
        "        store[\"A0\"] = X.T\n",
        " \n",
        "        A = store[\"A\" + str(self.L)]\n",
        "        dA = -np.divide(Y, A) + np.divide(1 - Y, 1 - A)\n",
        " \n",
        "        dZ = dA * self.sigmoid_derivative(store[\"Z\" + str(self.L)])\n",
        "        dW = dZ.dot(store[\"A\" + str(self.L - 1)].T) / self.n\n",
        "        db = np.sum(dZ, axis=1, keepdims=True) / self.n\n",
        "        dAPrev = store[\"W\" + str(self.L)].T.dot(dZ)\n",
        " \n",
        "        derivatives[\"dW\" + str(self.L)] = dW\n",
        "        derivatives[\"db\" + str(self.L)] = db\n",
        " \n",
        "        for l in range(self.L - 1, 0, -1):\n",
        "            dZ = dAPrev * self.sigmoid_derivative(store[\"Z\" + str(l)])\n",
        "            dW = 1. / self.n * dZ.dot(store[\"A\" + str(l - 1)].T)\n",
        "            db = 1. / self.n * np.sum(dZ, axis=1, keepdims=True)\n",
        "            if l > 1:\n",
        "                dAPrev = store[\"W\" + str(l)].T.dot(dZ)\n",
        " \n",
        "            derivatives[\"dW\" + str(l)] = dW\n",
        "            derivatives[\"db\" + str(l)] = db\n",
        " \n",
        "        return derivatives\n",
        " \n",
        "    def fit(self, X, Y, learning_rate=0.01, n_iterations=2500):\n",
        "        np.random.seed(1)\n",
        "        \n",
        "        self.n = X.shape[0]\n",
        " \n",
        "        self.layers_size.insert(0, X.shape[1])\n",
        " \n",
        "        self.initialize_parameters()\n",
        "        for loop in range(n_iterations):\n",
        "            A, store = self.forward(X)\n",
        "            cost = np.squeeze(-(Y.dot(np.log(A.T)) + (1 - Y).dot(np.log(1 - A.T))) / self.n)\n",
        "            derivatives = self.backward(X, Y, store)\n",
        " \n",
        "            for l in range(1, self.L + 1):\n",
        "                self.parameters[\"W\" + str(l)] = self.parameters[\"W\" + str(l)] - learning_rate * derivatives[\n",
        "                    \"dW\" + str(l)]\n",
        "                self.parameters[\"b\" + str(l)] = self.parameters[\"b\" + str(l)] - learning_rate * derivatives[\n",
        "                    \"db\" + str(l)]\n",
        " \n",
        "            if loop % 100 == 0:\n",
        "                print(cost)\n",
        "                self.costs.append(cost)\n",
        " \n",
        "    def predict(self, X, Y):\n",
        "        A, cache = self.forward(X)\n",
        "        n = X.shape[0]\n",
        "        p = np.zeros((1, n))\n",
        " \n",
        "        for i in range(0, A.shape[1]):\n",
        "            if A[0, i] > 0.5:\n",
        "                p[0, i] = 1\n",
        "            else:\n",
        "                p[0, i] = 0\n",
        " \n",
        "        print(\"Accuracy: \" + str(np.sum((p == Y) / n)))\n",
        " \n",
        "    def plot_cost(self):\n",
        "        plt.figure()\n",
        "        plt.plot(np.arange(len(self.costs)), self.costs)\n",
        "        plt.xlabel(\"epochs\")\n",
        "        plt.ylabel(\"cost\")\n",
        "        plt.show()\n",
        " \n",
        " \n",
        "def get_binary_dataset():\n",
        "    train_x_orig, train_y_orig, test_x_orig, test_y_orig = mnist.get_data()\n",
        " \n",
        "    index_5 = np.where(train_y_orig == 5)\n",
        "    index_8 = np.where(train_y_orig == 8)\n",
        " \n",
        "    index = np.concatenate([index_5[0], index_8[0]])\n",
        "    np.random.seed(1)\n",
        "    np.random.shuffle(index)\n",
        " \n",
        "    train_y = train_y_orig[index]\n",
        "    train_x = train_x_orig[index]\n",
        " \n",
        "    train_y[np.where(train_y == 5)] = 0\n",
        "    train_y[np.where(train_y == 8)] = 1\n",
        " \n",
        "    index_5 = np.where(test_y_orig == 5)\n",
        "    index_8 = np.where(test_y_orig == 8)\n",
        " \n",
        "    index = np.concatenate([index_5[0], index_8[0]])\n",
        "    np.random.shuffle(index)\n",
        " \n",
        "    test_y = test_y_orig[index]\n",
        "    test_x = test_x_orig[index]\n",
        " \n",
        "    test_y[np.where(test_y == 5)] = 0\n",
        "    test_y[np.where(test_y == 8)] = 1\n",
        " \n",
        "    return train_x, train_y, test_x, test_y\n",
        " \n",
        "def pre_process_data(train_x, test_x):\n",
        "    # Normalize\n",
        "    train_x = train_x / 255.\n",
        "    test_x = test_x / 255.\n",
        " \n",
        "    return train_x, test_x\n",
        " \n",
        " \n",
        "if __name__ == '__main__':\n",
        "    train_x, train_y, test_x, test_y = get_binary_dataset()\n",
        "\n",
        "    train_x, test_x = pre_process_data(train_x, test_x)\n",
        " \n",
        "    print(\"train_x's shape: \" + str(train_x.shape)) \n",
        "    print(\"test_x's shape: \" + str(test_x.shape))\n",
        " \n",
        "    layers_dims = [196, 1]\n",
        "    \n",
        " \n",
        "    ann = ANN(layers_dims)\n",
        "    ann.fit(train_x, train_y, learning_rate=0.1, n_iterations=1000)\n",
        "    ann.predict(train_x, train_y)\n",
        "    ann.predict(test_x, test_y)\n",
        "    ann.plot_cost()\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}